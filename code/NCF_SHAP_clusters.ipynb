{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb692ee5-4d24-4148-ae45-3243700d625e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:25:05.114571Z",
     "start_time": "2024-04-28T16:25:03.811703Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Softmax\n",
    "softmax = nn.Softmax()\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e9508d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T16:26:58.482991Z",
     "start_time": "2024-04-28T16:26:58.478903Z"
    }
   },
   "outputs": [],
   "source": [
    "DP_DIR = Path(\"processed_data\", \"Yahoo\") \n",
    "export_dir = Path(os.getcwd()).parent\n",
    "files_path = Path(export_dir, DP_DIR)\n",
    "checkpoints_path = Path(export_dir, \"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"Yahoo\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"NCF\" ## This notebook is for NCF\n",
    "\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir, DP_DIR)\n",
    "checkpoints_path = Path(export_dir, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9e302-c311-4beb-94f6-c6db1b63ee77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NCF recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a249c32-13e9-4324-97e4-3f4994a452e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, factor_num, num_layers,\n",
    "                    dropout, model, GMF_model=None, MLP_model=None, **kw):\n",
    "        super(NCF, self).__init__()\n",
    "        \"\"\"\n",
    "        user_num: number of users;\n",
    "        item_num: number of items;\n",
    "        factor_num: number of predictive factors;\n",
    "        num_layers: the number of layers in MLP model;\n",
    "        dropout: dropout rate between fully connected layers;\n",
    "        model: 'MLP', 'GMF', 'NeuMF-end', and 'NeuMF-pre';\n",
    "        GMF_model: pre-trained GMF weights;\n",
    "        MLP_model: pre-trained MLP weights.\n",
    "        \"\"\"        \n",
    "        self.dropout = dropout\n",
    "        self.model = model\n",
    "        self.GMF_model = GMF_model\n",
    "        self.MLP_model = MLP_model\n",
    "        self.device = kw['device']\n",
    "        user_size = kw['num_features']\n",
    "        item_size = kw['num_items']\n",
    "        self.embed_user_GMF = nn.Linear(user_size, factor_num, bias = False).to(self.device)\n",
    "        self.embed_item_GMF = nn.Linear(item_size, factor_num, bias = False).to(self.device)\n",
    "        self.embed_user_MLP = nn.Linear(\n",
    "                user_size, factor_num * (2 ** (num_layers - 1)), bias = False).to(self.device)\n",
    "        self.embed_item_MLP = nn.Linear(\n",
    "                item_size, factor_num * (2 ** (num_layers - 1)), bias = False).to(self.device)\n",
    "\n",
    "        MLP_modules = []\n",
    "        for i in range(num_layers):\n",
    "            input_size = factor_num * (2 ** (num_layers - i))\n",
    "            MLP_modules.append(nn.Dropout(p=self.dropout))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size//2).to(self.device))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        if self.model in ['MLP', 'GMF']:\n",
    "            predict_size = factor_num \n",
    "        else:\n",
    "            predict_size = factor_num * 2\n",
    "        self.predict_layer = nn.Linear(predict_size, 1).to(self.device)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self._init_weight_()\n",
    "        \n",
    "        self.embed_user_GMF.to(self.device)\n",
    "        self.embed_item_GMF.to(self.device)\n",
    "        self.embed_user_MLP.to(self.device)\n",
    "        self.embed_item_MLP.to(self.device)\n",
    "\n",
    "    def _init_weight_(self):\n",
    "        \"\"\" We leave the weights initialization here. \"\"\"\n",
    "        if not self.model == 'NeuMF-pre':\n",
    "            nn.init.normal_(self.embed_user_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_user_MLP.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_MLP.weight, std=0.01)\n",
    "\n",
    "            for m in self.MLP_layers:\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.kaiming_uniform_(self.predict_layer.weight, \n",
    "                                    a=1, nonlinearity='sigmoid')\n",
    "\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "        else:\n",
    "            # embedding layers\n",
    "            self.embed_user_GMF.weight.data.copy_(\n",
    "                            self.GMF_model.embed_user_GMF.weight)\n",
    "            self.embed_item_GMF.weight.data.copy_(\n",
    "                            self.GMF_model.embed_item_GMF.weight)\n",
    "            self.embed_user_MLP.weight.data.copy_(\n",
    "                            self.MLP_model.embed_user_MLP.weight)\n",
    "            self.embed_item_MLP.weight.data.copy_(\n",
    "                            self.MLP_model.embed_item_MLP.weight)\n",
    "\n",
    "            # mlp layers\n",
    "            for (m1, m2) in zip(\n",
    "                self.MLP_layers, self.MLP_model.MLP_layers):\n",
    "                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
    "                    m1.weight.data.copy_(m2.weight)\n",
    "                    m1.bias.data.copy_(m2.bias)\n",
    "\n",
    "            # predict layers\n",
    "            predict_weight = torch.cat([\n",
    "                self.GMF_model.predict_layer.weight, \n",
    "                self.MLP_model.predict_layer.weight], dim=1)\n",
    "            precit_bias = self.GMF_model.predict_layer.bias + \\\n",
    "                        self.MLP_model.predict_layer.bias\n",
    "\n",
    "            self.predict_layer.weight.data.copy_(0.5 * predict_weight)\n",
    "            self.predict_layer.bias.data.copy_(0.5 * precit_bias)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        if not self.model == 'MLP':\n",
    "            embed_user_GMF = self.embed_user_GMF(user)\n",
    "            embed_item_GMF = self.embed_item_GMF(item)\n",
    "            if embed_user_GMF.shape!=embed_item_GMF.shape:\n",
    "                user_res = torch.zeros(embed_item_GMF.shape).to(self.device)\n",
    "                user_res[:] = embed_user_GMF\n",
    "                embed_user_GMF = user_res\n",
    "            output_GMF = embed_user_GMF * embed_item_GMF\n",
    "        if not self.model == 'GMF':\n",
    "            embed_user_MLP = self.embed_user_MLP(user)\n",
    "            embed_item_MLP = self.embed_item_MLP(item)\n",
    "            if embed_user_MLP.shape!=embed_item_MLP.shape:\n",
    "                user_res = torch.zeros(embed_item_MLP.shape).to(self.device)\n",
    "                user_res[:] = embed_user_MLP\n",
    "                embed_user_MLP = user_res\n",
    "            interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
    "            output_MLP = self.MLP_layers(interaction)\n",
    "\n",
    "        if self.model == 'GMF':\n",
    "            concat = output_GMF\n",
    "        elif self.model == 'MLP':\n",
    "            concat = output_MLP\n",
    "        else:\n",
    "            concat = torch.cat((output_GMF, output_MLP), -1)\n",
    "\n",
    "        prediction = self.predict_layer(concat)\n",
    "        prediction = self.sigmoid(prediction)\n",
    "        return prediction.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0bb54-4774-40b1-93cc-b2017dbaa87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_model(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, **kw):\n",
    "        super(MLP_model, self).__init__()\n",
    "        self.device = kw['device']\n",
    "        user_size = kw['num_features']\n",
    "        item_size = kw['num_items']\n",
    "        factor_num = hidden_size\n",
    "        self.embed_user_MLP = nn.Linear(user_size, factor_num * (2 ** (num_layers - 1)), bias = False).to(self.device)\n",
    "        self.embed_item_MLP = nn.Linear(item_size, factor_num * (2 ** (num_layers - 1)), bias = False).to(self.device)\n",
    "        \n",
    "        MLP_modules = []\n",
    "        for i in range(num_layers):\n",
    "            input_size = factor_num * (2 ** (num_layers - i))\n",
    "            MLP_modules.append(nn.Dropout(p=0.5))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size//2).to(self.device))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "        \n",
    "        self.predict_layer = nn.Linear(hidden_size, 1, bias = True).to(self.device)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, user_tensor, item_tensor):\n",
    "        embed_user_MLP = self.embed_user_MLP(user_tensor.to(self.device))\n",
    "        embed_item_MLP = self.embed_item_MLP(item_tensor.to(self.device))\n",
    "        if embed_user_MLP.shape!=embed_item_MLP.shape:\n",
    "            user_res = torch.zeros(embed_item_MLP.shape).to(self.device)\n",
    "            user_res[:] = embed_user_MLP\n",
    "            embed_user_MLP = user_res\n",
    "        interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
    "        output_MLP = self.MLP_layers(interaction)\n",
    "        output = self.predict_layer(output_MLP)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fba303-984b-4262-80a9-1ddc21728c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF_model(nn.Module):\n",
    "    def __init__(self, hidden_size=8, **kw):\n",
    "        super(GMF_model, self).__init__()\n",
    "        self.device = kw['device']\n",
    "        user_size = kw['num_features']\n",
    "        item_size = kw['num_items']\n",
    "        self.embed_user_GMF = nn.Linear(user_size, hidden_size, bias = False).to(self.device)\n",
    "        self.embed_item_GMF = nn.Linear(item_size, hidden_size, bias = False).to(self.device)\n",
    "        self.predict_layer = nn.Linear(hidden_size, 1, bias = True).to(self.device)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, user_tensor, item_tensor):\n",
    "        user_vec = self.embed_user_GMF(user_tensor.to(self.device))\n",
    "        item_vec = self.embed_item_GMF(item_tensor.to(self.device))\n",
    "        if user_vec.shape!=item_vec.shape:\n",
    "            user_res = torch.zeros(item_vec.shape).to(self.device)\n",
    "            user_res[:] = user_vec\n",
    "            user_vec = user_res\n",
    "            \n",
    "        output = self.predict_layer(torch.mul(user_vec, item_vec))\n",
    "        \n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d560024-b0d6-4eb5-9b75-1d5af8ff4b05",
   "metadata": {},
   "source": [
    "## NCF Wrapper SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e03c4-9577-4697-a0f1-37c57fe0f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFWrapper(nn.Module):\n",
    "    def __init__(self, model, item_array, cluster_to_items, num_items, device):\n",
    "        super(NCFWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.n_items = num_items\n",
    "        self.cluster_to_items = cluster_to_items\n",
    "        self.item_array = torch.tensor(item_array, dtype=torch.float, device=device)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = torch.from_numpy(input).to(self.device).float()\n",
    "        n_clusters = 10\n",
    "        items = input[:, 0].long()\n",
    "        clusters = input[:, 1:].float()\n",
    "\n",
    "        user_vectors = torch.zeros((len(input), self.n_items), device=self.device, dtype=torch.float)\n",
    "        for cluster in range(n_clusters - 1):\n",
    "            user_vectors[:, self.cluster_to_items[cluster]] = clusters[:, cluster].unsqueeze(1)\n",
    "\n",
    "        item_vectors = self.item_array[items]\n",
    "\n",
    "        output = self.model(user_vectors, item_vectors)\n",
    "        return output.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cd649",
   "metadata": {},
   "source": [
    "# Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c265a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"NCF\": \"single\",\n",
    "    \"MLP\":\"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_0.0002_32_12.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\")\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\")}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184b2eb-4b83-41f9-85ea-4ff05e51e174",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "num_features = num_items_dict[data_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab96b4a-be4a-4b07-9c6e-d4727e56c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83191fc8-bc90-4eb7-98e3-e8744f656996",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "          'demographic':False,\n",
    "          'num_features':num_features,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_config= {\n",
    "\"enc_dims\": [512,128],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000\n",
    "}\n",
    "\n",
    "\n",
    "Pinterest_VAE_config= {\n",
    "\"enc_dims\": [256,64],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f547dcf8-fd78-4fe4-8fe5-be733ef1327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recommender():\n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        if data_name == \"Pinterest\":\n",
    "            recommender = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "        else:\n",
    "            recommender = VAE(VAE_config, **kw_dict)\n",
    "    elif recommender_name=='NCF':\n",
    "        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\n",
    "        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\n",
    "        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, model= 'NeuMF-pre', GMF_model= GMF_temp, MLP_model=MLP_temp, **kw_dict)\n",
    "    \n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "        \n",
    "    return recommender\n",
    "\n",
    "model = load_recommender()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f932393-f7c0-41ad-b651-d67969055b5b",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4912c-4e8e-4e48-b45e-6a506a5041c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'top1_test_{data_name}_{recommender_name}.pkl', 'rb') as f:\n",
    "    top1_test = pickle.load(f)\n",
    "    \n",
    "with open(f'top1_train_{data_name}_{recommender_name}.pkl', 'rb') as f:\n",
    "    top1_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99068cb0-964d-487e-a868-cd087283f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "u_train = torch.tensor(train_array).float()\n",
    "v_train = all_items_tensor\n",
    "user_ids = np.arange(train_array.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19ef80-9420-460a-add1-37701f7681c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "# Cluster items using k-means\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "k = 10\n",
    "\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "clusters = kmeans.fit_predict(np.transpose(u_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83450799-723c-4702-96df-e6bac066d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_clusters = kmeans.predict(np.transpose(u_train))\n",
    "\n",
    "# Create mapping from items to clusters\n",
    "item_to_cluster = {}\n",
    "# Create mapping from clusters to items\n",
    "cluster_to_items = {}\n",
    "for i, cluster in enumerate(item_clusters):\n",
    "    item_to_cluster[i] = cluster\n",
    "    if(cluster not in cluster_to_items.keys()):\n",
    "        cluster_to_items[cluster] = []\n",
    "    cluster_to_items[cluster].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25707482-0712-48c8-8a7d-51a072b97390",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test = torch.tensor(test_array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a537ef-c86a-4a16-9421-47bfe6a669e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters = np.zeros((u_test.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0764fa-a2da-4d7f-8432-9c490796284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters[:,i] = np.sum(u_test.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d147441-28cf-4fd5-b8d7-0cc108bc5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_bin =  np.where(user_to_clusters > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224823cf-fb89-4867-bebb-c5110504ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_train = np.zeros((u_train.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_value = 0\n",
    "target_items_test = list(top1_test.values())\n",
    "target_items_train = list(top1_train.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdad198-bf47-4386-beaa-10ce7bb0affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters_train[:,i] = np.sum(u_train.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a299d-0707-4e36-b80c-a46ca2931257",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_train_bin =  np.where(user_to_clusters_train > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a526e-b48b-4bcb-8d8a-2a2e450d144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col2 = list(top1_train.values())\n",
    "input_train_array= np.insert(user_to_clusters_train_bin, 0, col2, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b85d4a-67c4-4172-a345-c36ed8e8acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_test = np.zeros((u_test.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90deef-06f9-4546-9024-87a36d300a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters_test[:,i] = np.sum(u_test.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85921eb-56a9-44a2-8d5c-47ba762585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_test_bin =  np.where(user_to_clusters_test > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56400ccd-f840-4305-a35d-63a46d177b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = list(top1_test.values())\n",
    "input_test_array= np.insert(user_to_clusters_test_bin, 0, col1, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac0e6f-8469-4e67-b5ed-9a459f00c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_model = NCFWrapper(model, items_array, cluster_to_items, num_items, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f4bb2-79ba-476b-a433-c58ed73ba0c5",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c9f9b-6da6-474c-bcde-06f863f2cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeabb5c-44f3-442d-b4da-42e117989ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_subset = shap.sample(input_train_array,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd790e-2faa-40ce-8675-cbb7d62a5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(wrap_model,sampled_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0d53d-1a7d-480c-8c1b-983e5f27d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_test = explainer.shap_values(input_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fec20-d889-4c18-a660-9678c4662856",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = test_array[:,0]\n",
    "input_test_array= np.insert(shap_values_test, 0, col1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0faf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b302ae-f7b7-44e1-8650-0107bd13e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(item_to_cluster, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af2cc0-3efa-4f74-9a88-7f89d6bf0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'shap_values_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(input_test_array, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
