{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18831b05",
   "metadata": {},
   "source": [
    "### This notebook produces the metrics for a specific recommendation system and dataset for all the baselines.\n",
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160299a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import ipynb\n",
    "import importlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59163763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"MLP\" ### Can be MLP, VAE, NCF\n",
    "\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)\n",
    "checkpoints_path = Path(export_dir.parent, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56467a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2c01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "\n",
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a6b87",
   "metadata": {},
   "source": [
    "## Data and baselines imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b88a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "static_test_data = pd.read_csv(Path(files_path,f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115dc3f3-5d7b-4e8d-bb16-8fb13920fdf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_array = static_test_data.iloc[:,:-2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f572bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'jaccard_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    jaccard_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b5d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'cosine_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    cosine_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cc86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b9348-ad75-4e2f-8b31-75748a39255b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    item_to_cluster = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34114bbf-0762-4a56-9f27-4a616af8a27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'shap_values_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    shap_values= pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b741d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(num_items):\n",
    "    for j in range(i, num_items):\n",
    "        jaccard_dict[(j,i)]= jaccard_dict[(i,j)]\n",
    "        cosine_dict[(j,i)]= cosine_dict[(i,j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826d25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e9c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "           'num_features': num_items, \n",
    "            'demographic':False,\n",
    "          'pop_array':pop_array,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'static_test_data':static_test_data,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2db85e",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da5589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('../baselines') \n",
    "from ipynb.fs.defs.lime import *\n",
    "from ipynb.fs.defs.lime import *\n",
    "importlib.reload(ipynb.fs.defs.lime)\n",
    "from ipynb.fs.defs.lime import *\n",
    "lime = LimeBase(distance_to_proximity)\n",
    "\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "\n",
    "\n",
    "VAE_config= {\n",
    "\"enc_dims\": [512,128],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}\n",
    "\n",
    "\n",
    "Pinterest_VAE_config= {\n",
    "\"enc_dims\": [256,64],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63243da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_recommender():\n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        if data_name == \"Pinterest\":\n",
    "            recommender = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "        else:\n",
    "            recommender = VAE(VAE_config, **kw_dict)\n",
    "    elif recommender_name=='NCF':\n",
    "        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\n",
    "        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\n",
    "        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, model= 'NeuMF-pre', GMF_model= GMF_temp, MLP_model=MLP_temp, **kw_dict)\n",
    "    \n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "        \n",
    "    return recommender\n",
    "    \n",
    "recommender = load_recommender()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96048f75",
   "metadata": {},
   "source": [
    "# Baselines functions\n",
    "### Every function produces explanations for a designated baseline, resulting in a dictionary that maps items from the user's history to their explanation scores based on that baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48230a-38f5-4de5-aca4-d497264da059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#popularity mask\n",
    "def find_pop_mask(x, item_id):\n",
    "    user_hist = torch.Tensor(x).to(device) # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_pop_dict = {}\n",
    "    \n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            item_pop_dict[i]=pop_array[i] # add the pop of the item to the dictionary\n",
    "            \n",
    "    return item_pop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25797d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#User based similarities using Jaccard\n",
    "def find_jaccard_mask(x, item_id, user_based_Jaccard_sim):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_jaccard_dict = {}\n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            if (i,item_id) in user_based_Jaccard_sim:\n",
    "                item_jaccard_dict[i]=user_based_Jaccard_sim[(i,item_id)] # add Jaccard similarity between items\n",
    "            else:\n",
    "                item_jaccard_dict[i] = 0            \n",
    "\n",
    "    return item_jaccard_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950130f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cosine based similarities between users and items\n",
    "def find_cosine_mask(x, item_id, item_cosine):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_cosine_dict = {}\n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            if (i,item_id) in item_cosine:\n",
    "                item_cosine_dict[i]=item_cosine[(i,item_id)]\n",
    "            else:\n",
    "                item_cosine_dict[i]=0\n",
    "\n",
    "    return item_cosine_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fb4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lime_mask(x, item_id, min_pert, max_pert, num_of_perturbations, kernel_func, feature_selection, recommender, num_samples=10, method = 'POS', **kw_dict):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    lime.kernel_fn = kernel_func\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lime_args(user_hist, item_id, recommender, all_items_tensor, min_pert = min_pert, max_pert = max_pert, num_of_perturbations = num_of_perturbations, seed = item_id, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection, pos_neg='POS')\n",
    "    if method=='NEG':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection ,pos_neg='NEG')\n",
    "        \n",
    "    return most_pop_items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8194a-b8f3-4c3b-a111-0c73031318a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lire_mask(x, item_id, num_of_perturbations, kernel_func, feature_selection, recommender, proba=0.1, method = 'POS', **kw_dict):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    lime.kernel_fn = kernel_func\n",
    "\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lire_args(user_hist, item_id, recommender, all_items_tensor, train_array, num_of_perturbations = num_of_perturbations, seed = item_id, proba=0.1, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_of_perturbations, feature_selection, pos_neg='POS')\n",
    "    if method=='NEG':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_of_perturbations, feature_selection ,pos_neg='NEG')\n",
    "        \n",
    "    return most_pop_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a091550-2f30-49aa-baa2-2ecaecb03ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_fia_mask(user_tensor, item_tensor, item_id, recommender):\n",
    "    y_pred = recommender_run(user_tensor, recommender, item_tensor, item_id, **kw_dict).to(device)\n",
    "    items_fia = {}\n",
    "    user_hist = user_tensor.cpu().detach().numpy().astype(int)\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        if(user_hist[i] == 1):\n",
    "            user_hist[i] = 0\n",
    "            user_tensor = torch.FloatTensor(user_hist).to(device)\n",
    "            y_pred_without_item = recommender_run(user_tensor, recommender, item_tensor, item_id, 'single', **kw_dict).to(device)\n",
    "            infl_score = y_pred - y_pred_without_item\n",
    "            items_fia[i] = infl_score\n",
    "            user_hist[i] = 1\n",
    "\n",
    "    return items_fia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778184b0-ff25-4cbb-ad98-e506d0f83565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_shapley_mask(user_tensor, user_id, model, shap_values, item_to_cluster):\n",
    "    item_shap = {}\n",
    "    shapley_values = shap_values[shap_values[:, 0].astype(int) == user_id][:,1:]\n",
    "    user_vector = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    for i in np.where(user_vector.astype(int) == 1)[0]:\n",
    "        items_cluster = item_to_cluster[i]\n",
    "        item_shap[i] = shapley_values.T[int(items_cluster)][0]\n",
    "\n",
    "    return item_shap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a35c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, top_k):\n",
    "   \n",
    "    items_accent = defaultdict(float)\n",
    "    factor = top_k - 1\n",
    "    user_accent_hist = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    #Get topk items\n",
    "    sorted_indices = list(get_top_k(user_tensor, user_tensor, recommender_model, **kw_dict).keys())\n",
    "    \n",
    "    if top_k == 1:\n",
    "        # When k=1, return the index of the first maximum value\n",
    "        top_k_indices = [sorted_indices[0]]\n",
    "    else:\n",
    "        top_k_indices = sorted_indices[:top_k]\n",
    "   \n",
    "\n",
    "    for iteration, item_k_id in enumerate(top_k_indices):\n",
    "\n",
    "        # Set topk items to 0 in the user's history\n",
    "        user_accent_hist[item_k_id] = 0\n",
    "        user_tensor = torch.FloatTensor(user_accent_hist).to(device)\n",
    "       \n",
    "        item_vector = items_array[item_k_id]\n",
    "        item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "              \n",
    "        # Check influence of the items in the history on this specific item in topk\n",
    "        fia_dict = find_fia_mask(user_tensor, item_tensor, item_k_id, recommender_model)\n",
    "         \n",
    "        # Sum up all differences between influence on top1 and other topk values\n",
    "        if not iteration:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] *= factor\n",
    "        else:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] -= fia_dict[key]\n",
    "       \n",
    "    for key in items_accent.keys():\n",
    "        items_accent[key] *= -1    \n",
    "\n",
    "    return items_accent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb094e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cdcc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender_model, user_id = None, mask_type = None):\n",
    "    '''\n",
    "    This function invokes various explanation functions\n",
    "    and returns a dictionary of explanations, sorted by their scores.\n",
    "    '''\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "\n",
    "    if mask_type == 'lime':\n",
    "        POS_sim_items = find_lime_mask(user_vector, item_id, 50, 100, 150, distance_to_proximity,'highest_weights', recommender_model, num_samples=user_hist_size, **kw_dict)\n",
    "        NEG_sim_items = find_lime_mask(user_vector, item_id, 50, 100, 150, distance_to_proximity,'highest_weights', recommender_model, num_samples=user_hist_size, method = 'NEG', **kw_dict)\n",
    "    elif mask_type == 'lire':\n",
    "        POS_sim_items = find_lire_mask(user_vector, item_id, 200, distance_to_proximity,'highest_weights', recommender_model,proba = 0.1, **kw_dict)\n",
    "        NEG_sim_items = find_lire_mask(user_vector, item_id, 200, distance_to_proximity,'highest_weights', recommender_model,proba = 0.1, method = 'NEG', **kw_dict)\n",
    "    else:\n",
    "        if mask_type == 'pop':\n",
    "            sim_items = find_pop_mask(user_tensor, item_id)\n",
    "        elif mask_type == 'jaccard':\n",
    "            sim_items = find_jaccard_mask(user_tensor, item_id, jaccard_dict)\n",
    "        elif mask_type == 'cosine':\n",
    "            sim_items = find_cosine_mask(user_tensor, item_id, cosine_dict)\n",
    "        elif mask_type == 'shap':\n",
    "            sim_items = find_shapley_mask(user_tensor, user_id, recommender_model, shap_values, item_to_cluster)\n",
    "        elif mask_type == 'accent':\n",
    "            sim_items = find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, 5)\n",
    "\n",
    "        POS_sim_items = list(sorted(sim_items.items(), key=lambda item: item[1],reverse=True))[0:user_hist_size]\n",
    "        \n",
    "    return POS_sim_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be55f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender_model, expl_dict, **kw_dict):\n",
    "    POS_masked = user_tensor\n",
    "    NEG_masked = user_tensor\n",
    "    POS_masked[item_id]=0\n",
    "    NEG_masked[item_id]=0\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "    \n",
    "    \n",
    "    bins=[0]+[len(x) for x in np.array_split(np.arange(user_hist_size), num_of_bins, axis=0)]\n",
    "    \n",
    "    POS_at_5 = [0]*(len(bins))\n",
    "    POS_at_10=[0]*(len(bins))\n",
    "    POS_at_20=[0]*(len(bins))\n",
    "    \n",
    "    DEL = [0]*(len(bins))\n",
    "    INS = [0]*(len(bins))\n",
    "    NDCG = [0]*(len(bins))\n",
    "\n",
    "    \n",
    "    POS_sim_items = expl_dict\n",
    "    NEG_sim_items  = list(sorted(dict(POS_sim_items).items(), key=lambda item: item[1],reverse=False))\n",
    "    \n",
    "    total_items=0\n",
    "    for i in range(len(bins)):\n",
    "        total_items += bins[i]\n",
    "            \n",
    "        POS_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        \n",
    "        for j in POS_sim_items[:total_items]:\n",
    "            POS_masked[j[0]] = 1\n",
    "        POS_masked = user_tensor - POS_masked # remove the masked items from the user history\n",
    "\n",
    "        NEG_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        for j in NEG_sim_items[:total_items]:\n",
    "            NEG_masked[j[0]] = 1\n",
    "        NEG_masked = user_tensor - NEG_masked # remove the masked items from the user history \n",
    "        \n",
    "        POS_ranked_list = get_top_k(POS_masked, user_tensor, recommender_model, **kw_dict)\n",
    "        \n",
    "        if item_id in list(POS_ranked_list.keys()):\n",
    "            POS_index = list(POS_ranked_list.keys()).index(item_id)+1\n",
    "        else:\n",
    "            POS_index = num_items\n",
    "        NEG_index = get_index_in_the_list(NEG_masked, user_tensor, item_id, recommender_model, **kw_dict)+1\n",
    "\n",
    "        # for pos:\n",
    "        POS_at_5[i] = 1 if POS_index <=5 else 0\n",
    "        POS_at_10[i] = 1 if POS_index <=10 else 0\n",
    "        POS_at_20[i] = 1 if POS_index <=20 else 0\n",
    "\n",
    "        # for del:\n",
    "        DEL[i] = float(recommender_run(POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "\n",
    "        # for ins:\n",
    "        INS[i] = float(recommender_run(user_tensor-POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "\n",
    "        #for NDCG:\n",
    "        NDCG[i]= get_ndcg(list(POS_ranked_list.keys()),item_id, **kw_dict)\n",
    "        \n",
    "    res = [DEL, INS, NDCG, POS_at_5, POS_at_10, POS_at_20]\n",
    "    for i in range(len(res)):\n",
    "        res[i] = np.array(res[i])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132628b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_dictionaries = True # if it is the first time generating the explanations - assing \"True\"\n",
    "\n",
    "if create_dictionaries:\n",
    "    recommender.eval()\n",
    "    # Evaluate the model on the test set\n",
    "    \n",
    "    pop_expl_dict = {}\n",
    "    jaccard_expl_dict = {}\n",
    "    cosine_expl_dict = {}\n",
    "    lime_expl_dict = {}\n",
    "    lire_expl_dict = {}\n",
    "    accent_expl_dict = {}\n",
    "    shap_expl_dict = {}\n",
    "  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_array.shape[0]):\n",
    "        #for i in range(3):\n",
    "            if i%500 == 0:\n",
    "                print(i)\n",
    "            start_time = time.time()\n",
    "            user_vector = test_array[i]\n",
    "            user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "            user_id = int(test_data.index[i])\n",
    "\n",
    "            item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "            item_vector =  items_array[item_id]\n",
    "            item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "            user_vector[item_id] = 0\n",
    "            user_tensor[item_id] = 0\n",
    "\n",
    "            recommender.to(device)\n",
    "\n",
    "            pop_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'pop')\n",
    "            jaccard_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'jaccard')\n",
    "            cosine_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'cosine')\n",
    "            lime_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lime')\n",
    "            lire_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lire')\n",
    "            accent_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'accent')\n",
    "            shap_expl_dict[user_id] = single_user_expl(user_vector, user_tensor,item_id, item_tensor, num_items, recommender, mask_type= 'shap',user_id = user_id)\n",
    "\n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_pop_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(pop_expl_dict, handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_jaccard_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(jaccard_expl_dict, handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_cosine_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(cosine_expl_dict, handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_lime_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(lime_expl_dict, handle)\n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_lire_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(lire_expl_dict, handle)\n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_accent_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(accent_expl_dict, handle) \n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_shap_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(shap_expl_dict, handle)\n",
    "\n",
    "            \n",
    "else: #If it is not the first time you run the code - just read the picleks. Dont rewrite them\n",
    "        with open(Path(files_path,f'{recommender_name}_jaccard_expl_dict.pkl'), 'rb') as handle:\n",
    "            jaccard_expl_dict = pickle.load(handle) \n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_cosine_expl_dict.pkl'), 'rb') as handle:\n",
    "            cosine_expl_dict = pickle.load(handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_pop_expl_dict.pkl'), 'rb') as handle:\n",
    "            pop_expl_dict = pickle.load(handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_lime_expl_dict.pkl'), 'rb') as handle:\n",
    "            lime_expl_dict = pickle.load(handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_lire_expl_dict.pkl'), 'rb') as handle:\n",
    "            lire_expl_dict_200_clip = pickle.load(handle)\n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_accent_expl_dict.pkl'), 'rb') as handle:\n",
    "            accent_expl_dict = pickle.load(handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_shap_expl_dict.pkl'), 'rb') as handle:\n",
    "            shap_expl_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8febc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_one_expl_type(expl_name):\n",
    "    '''\n",
    "    This function aggregates explanations for all test users\n",
    "    and computes the average metric values across the entire test set.\n",
    "    '''\n",
    "    \n",
    "    print(f' ============ Start explaining {data_name} {recommender_name} by {expl_name} ============')\n",
    "    with open(Path(files_path,f'{recommender_name}_{expl_name}_expl_dict.pkl'), 'rb') as handle:\n",
    "        expl_dict = pickle.load(handle)\n",
    "    recommender.eval()\n",
    "    # Evaluate the model on the test set\n",
    "\n",
    "    num_of_bins = 11\n",
    "    \n",
    "    users_DEL = np.zeros(num_of_bins)\n",
    "    users_INS = np.zeros(num_of_bins)\n",
    "    NDCG = np.zeros(num_of_bins)\n",
    "    POS_at_5 = np.zeros(num_of_bins)\n",
    "    POS_at_10 = np.zeros(num_of_bins)\n",
    "    POS_at_20 = np.zeros(num_of_bins)\n",
    "\n",
    "    num_of_bins = 10\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_array.shape[0]):\n",
    "            start_time = time.time()\n",
    "            user_vector = test_array[i]\n",
    "            user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "            user_id = int(test_data.index[i])\n",
    "\n",
    "            item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "            item_vector =  items_array[item_id]\n",
    "            item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "            user_vector[item_id] = 0\n",
    "            user_tensor[item_id] = 0\n",
    "\n",
    "            user_expl = expl_dict[user_id]\n",
    "\n",
    "            res = single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender, user_expl, **kw_dict)\n",
    "            users_DEL += res[0]\n",
    "            users_INS += res[1]\n",
    "            NDCG += res[2]\n",
    "            POS_at_5 += res[3]\n",
    "            POS_at_10 += res[4]\n",
    "            POS_at_20 += res[5]\n",
    "\n",
    "            if i%500 == 0:\n",
    "                prev_time = time.time()\n",
    "                print(\"User {}, total time: {:.2f}\".format(i,prev_time - start_time))\n",
    "\n",
    "    a = i+1\n",
    "\n",
    "    print(f'users_DEL_{expl_name}: ', np.mean(users_DEL)/a)\n",
    "    print(f'users_INS_{expl_name}: ', np.mean(users_INS)/a)\n",
    "    print(f'NDCG_{expl_name}: ', np.mean(NDCG)/a)\n",
    "    print(f'POS_at_5_{expl_name}: ', np.mean(POS_at_5)/a)\n",
    "    print(f'POS_at_10_{expl_name}: ', np.mean(POS_at_10)/a)\n",
    "    print(f'POS_at_20_{expl_name}: ', np.mean(POS_at_20)/a)\n",
    "\n",
    "    print(np.mean(users_DEL)/a , np.mean(users_INS)/a, np.mean(NDCG)/a, np.mean(POS_at_5)/a, np.mean(POS_at_10)/a, np.mean(POS_at_20)/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d66300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expl_names_list = ['accent'] # specify the names of the baselines for which you wish to calculate the metrics values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c4d29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for expl_name in expl_names_list:\n",
    "    eval_one_expl_type(expl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a317a-b94e-4f27-b3a0-ed1ed79a493b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
