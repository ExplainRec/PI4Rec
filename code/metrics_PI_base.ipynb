{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "668ea0b7-73a8-4764-8318-433d0f94f74d",
   "metadata": {},
   "source": [
    "# This notebook contains the metrics calculation for the PI_Base (In which the baseline is the null vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26b726-af5c-40da-b1f7-0a2798e2ccbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports and initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af063889-a1b7-4f7c-bf9d-6fe7d6865f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:50.981242Z",
     "iopub.status.busy": "2024-04-30T06:24:50.980719Z",
     "iopub.status.idle": "2024-04-30T06:24:50.990849Z",
     "shell.execute_reply": "2024-04-30T06:24:50.990007Z",
     "shell.execute_reply.started": "2024-04-30T06:24:50.981198Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import ipynb\n",
    "import importlib\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33132c9c-2808-44b5-b272-2c523999fe2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:51.211727Z",
     "iopub.status.busy": "2024-04-30T06:24:51.211367Z",
     "iopub.status.idle": "2024-04-30T06:24:51.217969Z",
     "shell.execute_reply": "2024-04-30T06:24:51.216683Z",
     "shell.execute_reply.started": "2024-04-30T06:24:51.211692Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_dir = Path(os.getcwd()).parent\n",
    "checkpoints_path = Path(export_dir, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed7eb549-f84b-4029-b534-2748002cc882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:51.433428Z",
     "iopub.status.busy": "2024-04-30T06:24:51.433065Z",
     "iopub.status.idle": "2024-04-30T06:24:51.445543Z",
     "shell.execute_reply": "2024-04-30T06:24:51.444791Z",
     "shell.execute_reply.started": "2024-04-30T06:24:51.433393Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01ac2d-653d-486e-9a20-5804b1e79b3c",
   "metadata": {},
   "source": [
    "# Important to edit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6069496e-fdeb-4c91-adc6-50be1fe34931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:51.794116Z",
     "iopub.status.busy": "2024-04-30T06:24:51.793754Z",
     "iopub.status.idle": "2024-04-30T06:24:51.799726Z",
     "shell.execute_reply": "2024-04-30T06:24:51.798491Z",
     "shell.execute_reply.started": "2024-04-30T06:24:51.794081Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_names = [\"ML1M\"]\n",
    "#data_names = [\"ML1M\", \"Yahoo\", \"Pinterest\"]\n",
    "\n",
    "recommender_names = [\"MLP\"]\n",
    "# recommender_names = [\"MLP\", \"VAE\", \"NCF\"]\n",
    "\n",
    "expl_names_list = ['PI_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c71af70-25c6-40b9-85b2-2778bb7acffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:51.977520Z",
     "iopub.status.busy": "2024-04-30T06:24:51.977186Z",
     "iopub.status.idle": "2024-04-30T06:24:51.982595Z",
     "shell.execute_reply": "2024-04-30T06:24:51.981394Z",
     "shell.execute_reply.started": "2024-04-30T06:24:51.977485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_steps = 10 #For the interpolation steps in the PI precess - constant 10.\n",
    "\n",
    "method = \"base\"\n",
    "new_file_name = \"PI_check\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33efc769-46e0-470b-9f39-41202b02b7c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Functions form other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5e751d5-534a-44dd-95ab-23b3ea664447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:52.377769Z",
     "iopub.status.busy": "2024-04-30T06:24:52.377539Z",
     "iopub.status.idle": "2024-04-30T06:24:52.393269Z",
     "shell.execute_reply": "2024-04-30T06:24:52.392548Z",
     "shell.execute_reply.started": "2024-04-30T06:24:52.377746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "\n",
    "from ipynb.fs.defs.PI_functions import *\n",
    "importlib.reload(ipynb.fs.defs.PI_functions)\n",
    "from ipynb.fs.defs.PI_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d038c4f-4872-4f51-8e36-1cefe2a1a74b",
   "metadata": {},
   "source": [
    "# VAE confings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8a132d8-e097-4211-a8e4-8d422d85f3c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:52.781995Z",
     "iopub.status.busy": "2024-04-30T06:24:52.781635Z",
     "iopub.status.idle": "2024-04-30T06:24:52.788478Z",
     "shell.execute_reply": "2024-04-30T06:24:52.787080Z",
     "shell.execute_reply.started": "2024-04-30T06:24:52.781960Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VAE_config= {\n",
    "\"enc_dims\": [512,128],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}\n",
    "\n",
    "\n",
    "Pinterest_VAE_config= {\n",
    "\"enc_dims\": [256,64],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e9d35-4783-4793-a6b5-749c3225202c",
   "metadata": {},
   "source": [
    "# Load the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fabcade3-5840-4153-87b7-b56c2caa19a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:53.263038Z",
     "iopub.status.busy": "2024-04-30T06:24:53.262667Z",
     "iopub.status.idle": "2024-04-30T06:24:53.273570Z",
     "shell.execute_reply": "2024-04-30T06:24:53.272694Z",
     "shell.execute_reply.started": "2024-04-30T06:24:53.263002Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_recommender():\n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        if data_name == \"Pinterest\":\n",
    "            recommender = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "        else:\n",
    "            recommender = VAE(VAE_config, **kw_dict)\n",
    "    elif recommender_name=='NCF':\n",
    "        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\n",
    "        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\n",
    "        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, model= 'NeuMF-pre', GMF_model= GMF_temp, MLP_model=MLP_temp, **kw_dict)\n",
    "    \n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "        \n",
    "    return recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76850d-4eec-4270-bca9-1993453ca0f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6000cfdb-6f63-4d6c-9d84-92b1a2d912f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:54.968475Z",
     "iopub.status.busy": "2024-04-30T06:24:54.968116Z",
     "iopub.status.idle": "2024-04-30T06:24:54.977488Z",
     "shell.execute_reply": "2024-04-30T06:24:54.976244Z",
     "shell.execute_reply.started": "2024-04-30T06:24:54.968440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender_model, all_items_tensor, user_id = None, mask_type = None):\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "    \n",
    "    if mask_type == 'PI_base':\n",
    "        sim_items = find_ip_mask(model=recommender_model, user_tensor=user_tensor, item_id=item_id, all_items_tensor=all_items_tensor, num_steps=num_steps, method=method, device=device, recommender_name=recommender_name, train_array=train_array)   \n",
    "    else:\n",
    "        print (\"Wrong notebook!!\")\n",
    "        \n",
    "    POS_sim_items  = list(sorted(sim_items.items(), key=lambda item: item[1],reverse=True))[0:user_hist_size]\n",
    "    return POS_sim_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5874beaf-c840-4338-9161-e70e804621c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:55.519848Z",
     "iopub.status.busy": "2024-04-30T06:24:55.519486Z",
     "iopub.status.idle": "2024-04-30T06:24:55.537474Z",
     "shell.execute_reply": "2024-04-30T06:24:55.536644Z",
     "shell.execute_reply.started": "2024-04-30T06:24:55.519813Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender_model, expl_dict, **kw_dict):\n",
    "    POS_masked = user_tensor\n",
    "    NEG_masked = user_tensor\n",
    "    POS_masked[item_id]=0\n",
    "    NEG_masked[item_id]=0\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "    \n",
    "    \n",
    "    bins=[0]+[len(x) for x in np.array_split(np.arange(user_hist_size), num_of_bins, axis=0)]\n",
    "    \n",
    "    POS_at_5 = [0]*(len(bins))\n",
    "    POS_at_10=[0]*(len(bins))\n",
    "    POS_at_20=[0]*(len(bins))\n",
    "    \n",
    "    DEL = [0]*(len(bins))\n",
    "    INS = [0]*(len(bins))\n",
    "    NDCG = [0]*(len(bins))\n",
    "\n",
    "    \n",
    "    POS_sim_items = expl_dict\n",
    "    NEG_sim_items  = list(sorted(dict(POS_sim_items).items(), key=lambda item: item[1],reverse=False))\n",
    "    \n",
    "    total_items=0\n",
    "    for i in range(len(bins)):\n",
    "        total_items += bins[i]\n",
    "            \n",
    "        POS_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        \n",
    "        for j in POS_sim_items[:total_items]:\n",
    "            POS_masked[j[0]] = 1\n",
    "        POS_masked = user_tensor - POS_masked # remove the masked items from the user history\n",
    "\n",
    "        NEG_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        for j in NEG_sim_items[:total_items]:\n",
    "            NEG_masked[j[0]] = 1\n",
    "        NEG_masked = user_tensor - NEG_masked # remove the masked items from the user history \n",
    "        \n",
    "        POS_ranked_list = get_top_k(POS_masked, user_tensor, recommender_model, **kw_dict)\n",
    "        \n",
    "        if item_id in list(POS_ranked_list.keys()):\n",
    "            POS_index = list(POS_ranked_list.keys()).index(item_id)+1\n",
    "        else:\n",
    "            POS_index = num_items\n",
    "        NEG_index = get_index_in_the_list(NEG_masked, user_tensor, item_id, recommender_model, **kw_dict)+1\n",
    "\n",
    "        # for pos:\n",
    "        POS_at_5[i] = 1 if POS_index <=5 else 0\n",
    "        POS_at_10[i] = 1 if POS_index <=10 else 0\n",
    "        POS_at_20[i] = 1 if POS_index <=20 else 0\n",
    "\n",
    "        # for del:\n",
    "        DEL[i] = float(recommender_run(POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "\n",
    "        # for ins:\n",
    "        INS[i] = float(recommender_run(user_tensor-POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "\n",
    "        #for NDCG:\n",
    "        NDCG[i]= get_ndcg(list(POS_ranked_list.keys()),item_id, **kw_dict)\n",
    "        \n",
    "    res = [DEL, INS, NDCG, POS_at_5, POS_at_10, POS_at_20]\n",
    "    for i in range(len(res)):\n",
    "        res[i] = np.array(res[i])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5cd7de7-1d89-413f-bd29-9ddf21ce5cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:24:56.445540Z",
     "iopub.status.busy": "2024-04-30T06:24:56.445169Z",
     "iopub.status.idle": "2024-04-30T06:24:56.458736Z",
     "shell.execute_reply": "2024-04-30T06:24:56.457808Z",
     "shell.execute_reply.started": "2024-04-30T06:24:56.445505Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_one_expl_type(expl_name):\n",
    "    with open(new_file_name, \"a\") as file:\n",
    "        file.write(f' ============ Start explaining by {expl_name} ============\\n')\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_{expl_name}_expl_dict.pkl'), 'rb') as handle:\n",
    "            expl_dict = pickle.load(handle)\n",
    "        recommender.eval()\n",
    "        # Evaluate the model on the test set\n",
    "        \n",
    "        users_DEL = []\n",
    "        users_INS = []\n",
    "        NDCG = []\n",
    "        POS_at_5 = []\n",
    "        POS_at_10 = []\n",
    "        POS_at_20 = []\n",
    "    \n",
    "        num_of_bins=10\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i in range(test_array.shape[0]):\n",
    "            #for i in range(3):\n",
    "                start_time = time.time()\n",
    "                user_vector = test_array[i]\n",
    "                user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "                user_id = int(test_data.index[i])\n",
    "    \n",
    "                item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "                item_vector =  items_array[item_id]\n",
    "                item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "    \n",
    "                user_vector[item_id] = 0\n",
    "                user_tensor[item_id] = 0\n",
    "    \n",
    "                user_expl = expl_dict[user_id]\n",
    "    \n",
    "                res = single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender, user_expl, **kw_dict)\n",
    "                users_DEL.append(np.mean(res[0]))\n",
    "                users_INS.append(np.mean(res[1]))\n",
    "                NDCG.append(np.mean(res[2]))\n",
    "                POS_at_5.append(np.mean(res[3]))\n",
    "                POS_at_10.append(np.mean(res[4]))\n",
    "                POS_at_20.append(np.mean(res[5]))\n",
    "        \n",
    "        file.write(f\"{np.mean(POS_at_5)}, {np.mean(POS_at_10)}, {np.mean(POS_at_20)}, {np.mean(users_DEL)}, {np.mean(users_INS)}, {np.mean(NDCG)}\\n\")\n",
    "        file.write(f\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e11af-1c1c-4f47-baa9-b23e7696ed04",
   "metadata": {},
   "source": [
    "# START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b56d849-8a5a-4593-b332-7f615a9ff584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T06:25:00.232786Z",
     "iopub.status.busy": "2024-04-30T06:25:00.232426Z",
     "iopub.status.idle": "2024-04-30T06:31:26.071432Z",
     "shell.execute_reply": "2024-04-30T06:31:26.070269Z",
     "shell.execute_reply.started": "2024-04-30T06:25:00.232752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for data_name in data_names:\n",
    "    \n",
    "    DP_DIR = Path(\"processed_data\", data_name)\n",
    "    files_path = Path(export_dir, DP_DIR)\n",
    "\n",
    "    num_users = num_users_dict[data_name] \n",
    "    num_items = num_items_dict[data_name] \n",
    "    num_features = num_items_dict[data_name]\n",
    "        \n",
    "    with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "        pop_dict = pickle.load(f)\n",
    "    pop_array = np.zeros(len(pop_dict))\n",
    "    for key, value in pop_dict.items():\n",
    "        pop_array[key] = value\n",
    "\n",
    "    # Data \n",
    "    train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "    test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "    static_test_data = pd.read_csv(Path(files_path,f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "    \n",
    "    train_array = train_data.to_numpy()\n",
    "    test_array = test_data.to_numpy()\n",
    "    items_array = np.eye(num_items)\n",
    "    all_items_tensor = torch.Tensor(items_array).to(device)\n",
    "    test_array = static_test_data.iloc[:,:-2].to_numpy()\n",
    "\n",
    "    \n",
    "    for recommender_name in recommender_names:\n",
    "        output_type = output_type_dict[recommender_name]\n",
    "        hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "        \n",
    "        recommender_path = recommender_path_dict[(data_name,recommender_name)]\n",
    "\n",
    "        kw_dict = {'device':device,\n",
    "                  'num_items': num_items,\n",
    "                  'demographic':False,\n",
    "                  'num_features':num_features,\n",
    "                  'pop_array':pop_array,\n",
    "                  'all_items_tensor':all_items_tensor,\n",
    "                  'static_test_data':static_test_data,\n",
    "                  'items_array':items_array,\n",
    "                  'output_type':output_type,\n",
    "                  'recommender_name':recommender_name}\n",
    "\n",
    "\n",
    "        recommender = load_recommender()\n",
    "\n",
    "        file_mode = 'a' if os.path.exists(new_file_name) else 'w'\n",
    "        with open(new_file_name, file_mode) as file:\n",
    "            file.write(f' ============ This stats are for {data_name} dataset ============\\n')\n",
    "            file.write(f' ============ & for the recommender {recommender_name} ============\\n')\n",
    "            \n",
    "        for expl_name in expl_names_list:\n",
    "            if expl_name == \"PI_base\":\n",
    "                ip_expl_dict = {}\n",
    "\n",
    "                for i in range(test_array.shape[0]):\n",
    "                #for i in range(3):\n",
    "                    if i%500 == 0:\n",
    "                        print(i)\n",
    "                    user_vector = test_array[i]\n",
    "                    user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "                    user_id = int(test_data.index[i])\n",
    "\n",
    "                    item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "                    item_vector =  items_array[item_id]\n",
    "                    item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "                    user_vector[item_id] = 0\n",
    "                    user_tensor[item_id] = 0\n",
    "\n",
    "                    #This func calls find_ip_mask and in the mask the explainer is configurated\n",
    "                    ip_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, all_items_tensor=kw_dict['all_items_tensor'], mask_type= 'PI_base')\n",
    "\n",
    "                with open(Path(files_path,f'{recommender_name}_PI_base_expl_dict.pkl'), 'wb') as handle:\n",
    "                    pickle.dump(ip_expl_dict, handle)\n",
    "                            \n",
    "            eval_one_expl_type(expl_name)\n",
    "            \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb28f9-9a55-4f65-bdb3-8bad9417a5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b92dd1-d7b5-4ac7-9522-b2957a7acb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6b83a-52b3-4d79-9ac0-558606e19715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549448e8-e831-44d7-aa7c-96e57966c44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64329f8-1ce6-4f50-b59d-8751c8fe1ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb5cfc-d911-4b14-8b34-597ab77c2006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175bf1e-1adc-4078-ac35-123b47a00a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
